
![](04_hdfs整体架构原理(2).png)

基本上来说，可以把hdfs当做是linux上的文件系统来操作，命令基本上都是差不多的

在hdfs上创建目录，hadoop fs -mkdir -p /user/dir01，创建一个目录层级结构

hadoop fs -rmr，删除目录，mv、cp

linux上是差不多的，hadoop fs -put可以上传本地的大文件到hdfs上去，hadoop fs -get可以将hdfs上的文件给下载下来

形成一系列的文件系统的元数据

目录层级结构，以及目录里有哪些文件，文件 -> block -> 在哪个datanode上面

元数据，是放在namenode上面

每个大文件实际的内容，会被拆分为多个block，放到各个datanode上面去分布式存储


hdfs说白了支持的数据结构，不是mysql那种关系型数据库的库表结构，他支持的是文件系统的层级结构，就是目录-子目录-文件的
这种形式。当然其实hadoop生态必然是可以支持类似关系型数据库的库表结构的，但是那是基于hdfs的一个开源项目，hive，干的
事儿了，他是针对大数据的数据仓库技术

所以说，基于hdfs就可以创建目录啊，创建文件啊，对文件读写数据啊，然后移动文件啊，删除文件啊，重命名文件啊，balabala的，
你能在你win10电脑上的文件的操作，大部分都能在hdfs上干

而且人家hdfs还支持对文件进行quotas就是配额的限制，类似于说限制你某个目录最多只能占用多少磁盘空间了，就这个意思；还支持
对文件的权限操作，比如说针对某个用户，对某个目录，可以读，但是不能写，这个文件权限后面讲吧，其实跟linux的文件权限是类似
的

所以hdfs支持的文件系统的操作还是蛮丰富的，但是比如linux的一些hard link、soft link之类的概念是不支持的

然后呢，这一整套文件系统相关的元数据，就是目录层级结构，文件，文件和block对应关系，block和datanode对应关系，还有别的文件
的一些quotas和权限之类的各种东东，都是存放在namenode里的，这就是所谓的文件系统元数据，英文是：filesystem metadata

你反正对文件的一些比如创建目录拉、删除文件了、重命名文件了，之类的涉及到元数据的操作，都是交给namenode来干的。那么你找
人家namenode修改元数据的时候，人家是怎么管理元数据的呢

namenode里有一个东西叫做EditLog，就是编辑操作日志的概念，你比如说创建个目录，那么人家namenode必然往这个edits log里写入
一条日志，然后你创建个文件，人家还会再写入一条日志，这个edit log是放在磁盘上的一个日志文件。然后呢，比如整个文件目录组
织结构，以及block、datanode的映射关系啊，这些东西存储在FsImage文件里，这个fsimage也是放在磁盘上的文件

然后呢，namenode除了在fsimage文件里存放元数据，还会在内存里保存一份儿，要不然这种元数据，动不动读写文件，不是害死人了，
性能绝对是很差的。然后呢，namenode每隔一段时间（这个时间间隔是自己配置的，一个threshold），就会读取磁盘里的edits log
出来，全部应用到内存里的fsimage缓存里去，然后将fsimage重新写一份到磁盘里去，接着将edits log给给清空掉

这个操作叫做checkpoint操作，这个checkpoint的时间间隔自己可以配置的。然后在namenode启动的时候，人家也是会从磁盘上读取
edits log和fsimage在内存里构造一份缓存数据的

这个checkpoint可以自己配置的，dfs.namenode.checkpoint.period，这个参数配置几秒钟执行一次checkpoint，还有一个，
dfs.namenode.checkpoint.txns，这个参数配置当edits log里有多少条数据的时候，就执行一次checkpoint




