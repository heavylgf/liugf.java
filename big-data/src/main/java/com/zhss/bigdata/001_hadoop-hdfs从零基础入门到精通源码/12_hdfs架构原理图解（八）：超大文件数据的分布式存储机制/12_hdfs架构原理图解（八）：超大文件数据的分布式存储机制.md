
![](04_hdfs整体架构原理(7).png)

你要是比如往一个文件里写数据，那么肯定就是会在namenode那里根据文件的大小，将这个文件拆分为多个block的，每个block存储一部分数据，每个block是有固定大小的，以前老版本的hdfs都是一个block 64mb的，那太小了，现在一般都是一个block是128mb（目前默认的），或者是256mb比较合适

然后人家namenode会规定好的，哪个block放到哪个datanode上去，他会尽量让各个datanode均衡点儿，然后实际上你的文件就会被hdfs的client拆分为多个block写到各个datanode上去了，datanode把每个block就在自己本地磁盘上存为一个文件就ok了

datanode肯定不会傻到说是把所有文件都放在一个目录里的，那会导致linux的文件读写出问题的，他会建立一个合适的子目录层级结构，建立很多的子目录，然后保证每个目录中的文件数量不会过多

datanode每次启动的时候，都会扫描文件系统里的数据然后生成一份自己本地保存了哪些block的list数据，然后报告给namenode，namenode会做一些同步比对、校验啊之类的事情的。



