
![](026_2、kafka高吞吐低延迟（零拷贝）%20(12).png)


所谓的leader epoch大致理解为每个leader的版本号，以及自己是从哪个offset开始写数据的，类似[epoch = 0, offset = 0]，这个
就是epoch是版本号的意思，接着的话，按照之前的那个故障场景

假如说follower先宕机再重启，他会找leader继续同步最新的数据，更新自己的LEO和HW，不会截断数据，因为他会看看自己这里有没有
[epoch, offset]对，如果有的话，除非是自己的offset大于了leader的offset，才会截断自己的数据

而且人家leader的最新offset = 1，自己的offset = 0，明显自己落后于人家，有什么资格去截断数据呢？对不对，就是这个道理。
而且还会去从leader同步最新的数据过来，此时自己跟Leader数据一致。

如果此时leader宕机，切换到follower上，此时就会更新自己的[epoch = 1, offset = 2]，意思是自己的leader版本号是epoch = 1，
自己从offset = 2开始写数据的

然后接着老leader恢复变为follower，从新leader看一下epoch跟自己对比，人家offset = 2，自己的offset = 0，也不需要做任何数据
截断，直接同步人家数据就可以了

然后针对数据不一致的场景，如果说老leader恢复之后作为follower，从新leader看到[epoch = 1, offset = 1]，此时会发现自己的
offset也是1，但是人家新leader是从offset = 1开始写的，自己的offset = 1怎么已经有数据了呢？

此时就会截断掉自己一条数据，然后跟人家同步保持数据一致


