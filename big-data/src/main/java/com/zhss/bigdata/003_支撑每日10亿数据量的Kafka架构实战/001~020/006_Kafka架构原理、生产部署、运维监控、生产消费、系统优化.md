
kafka这个实战的课程，分为哪几个环节和步骤去讲

业务背景已经交代的比较清楚了，就是对kafka架构原理做比较深入的研究，先明白kafka的工作原理，玩儿kafak

我们就可以基于这个项目背景，来看看kafka生产环境的部署怎么来规划，每台机器的配置，参数设置，需要多少台机器，抗每天10亿数据量

对集群日常的管理、运维、监控，学习一下是怎么来做的

研究一下，如果你要往kafka里写数据，他是怎么来写的，写数据客户端的原理是什么；如果从kafka里读数据，他是怎么来读的，读数据客户端
的原理是什么

就要来研究一下kafka生产环境遇到的问题：数据丢失、数据顺序、数据积压、吞吐量优化、高可用保障、生产端的优化、消费端的优化、JVM优化、
性能的优化，系统优化

hdfs和kafka都有了，接下来就可以玩儿各种数据的采集了，用户行为日志，基于真实的几十张报表的需求，来反向研究，当你遇到真实的数据分析
需求的时候，数据埋点应该怎么来做，用户日志怎么来采集，离线导入hdfs，实时导入kafka

数据库业务数据采集，研究canal的源码，自研一套数据同步中间件，可以把数据库的业务数据库离线导入Hdfs，实时导入kafka

爬虫，基于java自研一套分布式爬虫系统，分布式是个关键点，N多个爬虫系统协作起来分布式抓取数据，离线导入hdfs，实时导入kafka

数据采集这个大的项目就做完了，hdfs有离线数据，kafka有实时数据，而且分别有行为日志、业务数据、竞对数据，三种数据在离线和实时两种存储
里都有

离线数据仓库，实时数据平台，基于真实的电商的需求来做，尽可能100张报表的真实需求来反向驱动

