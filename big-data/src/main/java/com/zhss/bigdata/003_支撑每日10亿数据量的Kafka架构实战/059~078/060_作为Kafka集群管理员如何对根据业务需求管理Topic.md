
手头已经有了一套生产集群了，都部署好了，压力测试过后集群整体抗个每秒几十万的请求都可以做到了，支撑几十TB的数据量都可以了

平时作为kafka平台工程师，你需要协助业务团队来维护topic，各个业务团队，小公司，主要就是一个后端技术团队，或者是大数据
技术团队，你自己本身也是大数据技术团队里面的一个人，只不过你的leader专门让你来负责维护kafka集群

比如说你们团队里，有的哥儿们是做实时计算这块的，他需要把实时的数据流引入到kafka里去，接着他会需要去使用flink、
spark streaming、storm，这种实时计算技术，来从kafka里消费数据，接着继续去运算，做实时的一些分析

风控技术团队，推荐技术团队，他们可能也需要将一些实时的数据流引入到kafka，或者是人家直接从你这里获取实时的数据流，
进行风控，或者是实时的个性化推荐，可能性都有，所以他们就是你的业务方

bin/kafka-topics.sh --create --zookeeper localhost:2181 --partitions 6 --replication-factor 2 --topic test01

创建topic其实主要是指定这个topic的分区数量，具体来说你要综合考虑Kafka集群的整体规模，有几台机器，还有就是这个topic最近
7天的数据量会有多大。举个例子，某个topic每天要放用户行为日志

每天大概是1GB的数据量，最近7天就需要保留7GB的数据量，还有两个副本因子，那么就是一共14GB的数据量。现在假设Kafka集群有
4台物理机，你觉得应该给这个Topic分配多少个分区？

很明显了，就4个分区就足够了，每台机器会放一个leader partition，然后都有一个follower partition，这样这个topic的数据会
均匀分散在4台机器上，而且对这个topic的读写请求都均匀分散在4台机器上了

假设说你对这个topic每秒写入并发是10万条，4个分区，写入的时候会写入4个分区，在4台机器上有leader partition，均匀的分散在
4台机器上，每台机器其实就是大概每秒写入2.5万个请求

那如果你的Kafka物理集群有20台机器呢？这个时候初始分区数量可以设置为7，把7个分区分散在其中的7台机器上，这样的好处，就是
对这个Topic的读写请求会均匀分散在7台机器上上，对Topic的读写吞吐量是不是会更高？

所以在创建Topic的时候，大家一定要考虑好这一点，至于说副本因子的话，其实一般就是2就足够了，因为双副本可以保证一定的数据
容错性，哪怕一台机器宕机了，还有其他副本保证数据不丢失，可以继续使用

如果你设置为3副本，那当然更好了，最多允许2台机器宕机不会丢数据，但是问题是你的数据存储空间会triple一下，那你的机器资源
就会耗费更多了，所以这里要权衡一下。如果希望数据严格不丢失

那么min.insync.replicas，那个参数可以设置为2，要求比如ISR里有2个副本，才能写入成功，acks=-1，就是必须写入2个副本才行，
这样可以保证写成功了一条数据，绝对一般是数据不会丢的

对于大数据的场景，要求的是吞吐量，而不是数据不丢失

但是如果要求更高的吞吐量，那么就设置min.insync.replicas，这个参数就是设置为1就可以了，只要有1个副本就可以写入，写入1个
副本就算写成功，也就是写入leader就够了，可能数据会丢失，但是吞吐量很高，因为写入不需要等待副本同步成功

通常情况下建议采取高吞吐的策略，不要为了数据0丢失牺牲掉吞吐量，除非是极为核心的业务数据，比如说广告计费的数据

bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic test01，可以删除topic

如果要删除topic，需要设置delete.topic.enable为true，允许用户删除topic，删除之后是后台异步执行的，要过很长时间才能
删除掉topic

bin/kafka-topics.sh --zookeeper localhost:2181 --list，可以查看topic列表，通过这个命令可以快速查看当前有哪些topic，还有
就是可以看看要删除的topic删除掉了没有，平时这个命令管理员用的是很多的

bin/kafka-topics.sh --zookeeper 192.168.101.130:2181,192.168.101.131:2181,192.168.101.132 --list

bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test01，可以查看topic详情，这个命令其实相当的实用，
因为平时肯定要经常看看一个topic的具体情况，每个partition的leader在哪台机器上，副本在哪些机器上，ISR列表

bin/kafka-topics.sh --zookeeper 192.168.101.130:2181,192.168.101.131:2181,192.168.101.132:2181 --describe --topic test




