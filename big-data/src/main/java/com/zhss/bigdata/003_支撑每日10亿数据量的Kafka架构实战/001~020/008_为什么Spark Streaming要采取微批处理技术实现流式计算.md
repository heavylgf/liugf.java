
如果来一条数据就处理一条数据，可能会导致每条数据要处理假设1毫秒，那么此时每秒可以处理1000条数据，这就是每秒的吞吐量，但是如果采用
微批处理技术呢？比如说把9毫秒内的数据收集起来一共有1000条数据，接着一次性交给引擎来处理，1毫秒就把1000条数据给处理完了。

Kafka现在采取batch思路，10毫秒处理了1000条数据，每个系统发送数据过来到处理完成花费10毫秒，延迟提高了10倍，Kafka的吞吐量提高了，
每秒可以处理10万条数据，吞吐量是提升了100倍。

那么就相当于是10毫秒处理了1000条数据，每秒可以处理10万条数据，吞吐量是不是就提升了100倍？

这个就是所谓的流式计算采用的微批处理技术，你一条一条处理，每条数据都需要启动新的计算资源，有网络开销，甚至是磁盘开销。但是你一次性处理
1000条，跟你一次性处理1条其实是差不多的

因为用的计算资源什么都差不多，但是在内存里一下子可以处理完1000条数据

这就是说，提升了吞吐量，但是计算的延时就增加了，一条数据过来，需要10毫秒之后才能处理完毕。但是你要是降低计算的延时，那么吞吐量就降低了，
数据来了1毫秒就处理完毕，但是每秒能处理的数据量太少了


